2024-12-07 08:37:42,240 - Run with SimGCL on amazon-book
2024-12-07 08:37:42,240 - dataset:amazon-book	num_users:52643, num_items:91599 	|num_train:2380726, num_test:603382, sparsity: 0.999381
2024-12-07 08:37:48,002 - dataset_path : ./dataset/
2024-12-07 08:37:48,003 - dataset : amazon-book
2024-12-07 08:37:48,003 - top_K : [20]
2024-12-07 08:37:48,003 - training_epochs : 20
2024-12-07 08:37:48,003 - early_stopping : 20
2024-12-07 08:37:48,003 - interval : 1
2024-12-07 08:37:48,003 - embedding_size : 64
2024-12-07 08:37:48,005 - batch_size : 2048
2024-12-07 08:37:48,005 - test_batch_size : 2048
2024-12-07 08:37:48,005 - learn_rate : 0.001
2024-12-07 08:37:48,006 - reg_lambda : 0.0001
2024-12-07 08:37:48,006 - GCN_layer : 3
2024-12-07 08:37:48,006 - ssl_lambda : 2.0
2024-12-07 08:37:48,006 - temperature : 0.2
2024-12-07 08:37:48,006 - epsilon : 0.1
2024-12-07 08:37:48,006 - sparsity_test : 0
2024-12-07 08:40:41,740 - Epoch:    1 | Training time: 173.722 | training loss: 12.978265 = 0.688728 + 3.5e-05 + 12.289503
2024-12-07 08:40:57,646 - Epoch:    1 | Test recall: [0.04493767] | Test NDCG: [0.03622256]
2024-12-07 08:43:50,401 - Epoch:    2 | Training time: 172.755 | training loss: 12.455388 = 0.678458 + 0.000135 + 11.776795
2024-12-07 08:44:06,155 - Epoch:    2 | Test recall: [0.03774132] | Test NDCG: [0.03075296]
2024-12-07 08:46:58,548 - Epoch:    3 | Training time: 172.392 | training loss: 12.353755 = 0.665956 + 0.000267 + 11.687532
2024-12-07 08:47:14,323 - Epoch:    3 | Test recall: [0.03015265] | Test NDCG: [0.02462062]
2024-12-07 08:50:06,376 - Epoch:    4 | Training time: 172.052 | training loss: 12.294207 = 0.649961 + 0.000438 + 11.643808
2024-12-07 08:50:21,721 - Epoch:    4 | Test recall: [0.02705361] | Test NDCG: [0.02199753]
2024-12-07 08:53:13,425 - Epoch:    5 | Training time: 171.703 | training loss: 12.247652 = 0.629125 + 0.000663 + 11.617864
2024-12-07 08:53:28,817 - Epoch:    5 | Test recall: [0.02679951] | Test NDCG: [0.0218105]
2024-12-07 08:56:21,205 - Epoch:    6 | Training time: 172.385 | training loss: 12.204463 = 0.601425 + 0.000966 + 11.602072
2024-12-07 08:56:36,462 - Epoch:    6 | Test recall: [0.02882112] | Test NDCG: [0.02340374]
2024-12-07 08:59:28,614 - Epoch:    7 | Training time: 172.151 | training loss: 12.160044 = 0.565796 + 0.001378 + 11.59287
2024-12-07 08:59:44,366 - Epoch:    7 | Test recall: [0.03203104] | Test NDCG: [0.02614422]
2024-12-07 09:02:36,678 - Epoch:    8 | Training time: 172.310 | training loss: 12.111899 = 0.522327 + 0.001932 + 11.587641
2024-12-07 09:02:51,983 - Epoch:    8 | Test recall: [0.03613364] | Test NDCG: [0.02958223]
2024-12-07 09:05:43,985 - Epoch:    9 | Training time: 172.001 | training loss: 12.060532 = 0.472161 + 0.002658 + 11.585713
2024-12-07 09:05:59,248 - Epoch:    9 | Test recall: [0.04024454] | Test NDCG: [0.03299515]
2024-12-07 09:08:51,667 - Epoch:   10 | Training time: 172.418 | training loss: 12.007355 = 0.418134 + 0.003569 + 11.585652
2024-12-07 09:09:07,932 - Epoch:   10 | Test recall: [0.0441747] | Test NDCG: [0.03613896]
2024-12-07 09:12:00,615 - Epoch:   11 | Training time: 172.683 | training loss: 11.956085 = 0.364838 + 0.004655 + 11.586593
2024-12-07 09:12:16,485 - Epoch:   11 | Test recall: [0.04712357] | Test NDCG: [0.03841486]
2024-12-07 09:15:08,597 - Epoch:   12 | Training time: 172.111 | training loss: 11.90964 = 0.316259 + 0.005876 + 11.587506
2024-12-07 09:15:24,276 - Epoch:   12 | Test recall: [0.0490721] | Test NDCG: [0.0397863]
2024-12-07 09:18:16,960 - Epoch:   13 | Training time: 172.683 | training loss: 11.869148 = 0.274298 + 0.007183 + 11.587667
2024-12-07 09:18:32,681 - Epoch:   13 | Test recall: [0.05026051] | Test NDCG: [0.04063947]
2024-12-07 09:21:24,943 - Epoch:   14 | Training time: 172.262 | training loss: 11.835363 = 0.239896 + 0.008529 + 11.586938
2024-12-07 09:21:40,958 - Epoch:   14 | Test recall: [0.05083071] | Test NDCG: [0.04099026]
2024-12-07 09:24:33,086 - Epoch:   15 | Training time: 172.128 | training loss: 11.807598 = 0.212103 + 0.009874 + 11.58562
2024-12-07 09:24:49,170 - Epoch:   15 | Test recall: [0.05119717] | Test NDCG: [0.04113328]
2024-12-07 09:27:41,364 - Epoch:   16 | Training time: 172.194 | training loss: 11.784661 = 0.189635 + 0.011192 + 11.583834
2024-12-07 09:27:57,026 - Epoch:   16 | Test recall: [0.05131643] | Test NDCG: [0.04111736]
2024-12-07 09:30:48,984 - Epoch:   17 | Training time: 171.957 | training loss: 11.766066 = 0.171812 + 0.012467 + 11.581787
2024-12-07 09:31:05,154 - Epoch:   17 | Test recall: [0.0512511] | Test NDCG: [0.04101985]
2024-12-07 09:33:57,169 - Epoch:   18 | Training time: 172.015 | training loss: 11.7504 = 0.157332 + 0.013688 + 11.579379
2024-12-07 09:34:13,259 - Epoch:   18 | Test recall: [0.05129348] | Test NDCG: [0.04089628]
2024-12-07 09:37:06,063 - Epoch:   19 | Training time: 172.802 | training loss: 11.737195 = 0.145073 + 0.014856 + 11.577265
2024-12-07 09:37:22,273 - Epoch:   19 | Test recall: [0.05114037] | Test NDCG: [0.04070821]
2024-12-07 09:40:14,577 - Epoch:   20 | Training time: 172.304 | training loss: 11.726466 = 0.135322 + 0.015969 + 11.575175
2024-12-07 09:40:30,724 - Epoch:   20 | Test recall: [0.05085184] | Test NDCG: [0.04046493]
2024-12-07 09:40:30,724 - Model training process completed.
2024-12-07 09:40:30,724 - Best epoch:   16 | Best recall: [0.05131643] | Best NDCG: [0.04111736]